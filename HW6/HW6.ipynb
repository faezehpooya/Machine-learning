{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cvxopt\n",
    "import cvxopt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.utils import shuffle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section A\n",
    "\n",
    "all_X, all_y = load_digits(return_X_y=True)\n",
    "\n",
    "all_X = np.array(all_X)\n",
    "all_y = np.array(all_y)\n",
    "all_X, all_y = shuffle(all_X, all_y)\n",
    "\n",
    "def normalize(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0: \n",
    "        return v\n",
    "    return v / norm\n",
    "\n",
    "all_X = np.apply_along_axis(normalize, axis=1, arr=all_X)\n",
    "\n",
    "\n",
    "len_test = int(0.1*len(all_X))\n",
    "len_train = len(all_X) - len_test\n",
    "test_ind = np.array([np.random.choice(np.where(all_y == i)[0], 15, replace=False) for i in range(10)]).reshape(1, 150)\n",
    "test_ind = np.concatenate((test_ind, \n",
    "                           np.random.choice(np.setdiff1d(range(len(all_y)), \n",
    "                                                         test_ind), len_test - 150, replace=False)), axis=None)\n",
    "test_X, test_Y = all_X[test_ind], all_y[test_ind]\n",
    "train_X, train_Y = all_X[np.setdiff1d(range(len(all_y)), test_ind)], all_y[np.setdiff1d(range(len(all_y)), test_ind)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearKernel:\n",
    "    def __init__(self, theta=None):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, X, Y):\n",
    "        return X @ Y.T\n",
    "    \n",
    "    \n",
    "class GaussianKernel:\n",
    "    def __init__(self, theta):\n",
    "        self.theta = theta\n",
    "        \n",
    "    def __call__(self, X, Y):\n",
    "        if (X.ndim == 1) and (Y.ndim == 1):\n",
    "            tmp = np.linalg.norm(X - Y)**2\n",
    "        elif ((X.ndim == 1) and (Y.ndim != 1)) or ((X.ndim != 1) and (Y.ndim == 1)):\n",
    "            tmp = np.linalg.norm(X - Y, axis=1)**2\n",
    "        else:\n",
    "            tmp = np.reshape(np.sum(X**2,axis=1), (len(X), 1)) + np.sum(Y**2, axis=1)  -2 * (X @ Y.T)\n",
    "        K = np.exp(- tmp/(2*self.theta**2))\n",
    "        return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvxopt_solve_qp(P, q, G=None, h=None, A=None, b=None):\n",
    "    \n",
    "#     P = .5 * (P + P.T)  # make sure P is symmetric\n",
    "    args = [cvxopt.matrix(P), cvxopt.matrix(q)]\n",
    "    if G is not None:\n",
    "        args.extend([cvxopt.matrix(G), cvxopt.matrix(h)])\n",
    "        if A is not None:\n",
    "            args.extend([cvxopt.matrix(A), cvxopt.matrix(b)])\n",
    "            \n",
    "\n",
    "    #Setting solver parameters (change default to decrease tolerance) \n",
    "    cvxopt.solvers.options['show_progress'] = False\n",
    "    cvxopt.solvers.options['abstol'] = 1e-10\n",
    "    cvxopt.solvers.options['reltol'] = 1e-10\n",
    "    cvxopt.solvers.options['feastol'] = 1e-10\n",
    "\n",
    "    sol = cvxopt.solvers.qp(*args)\n",
    "    if 'optimal' not in sol['status']:\n",
    "        return None\n",
    "    \n",
    "    return np.array(sol['x']).reshape(1, -1)[0]\n",
    "\n",
    "\n",
    "class SVC:\n",
    "    def __init__(self, kernel, C=1.0):\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "          \n",
    "    def fit(self, X, t, tol_conv=1e-6, tol_sv=1e-4, show_time = False): \n",
    "\n",
    "        n,m = X.shape\n",
    "        y = t.reshape(-1,1) * 1.\n",
    "        X_dash = y * X\n",
    "        H = np.dot(X_dash , X_dash.T) * 1.\n",
    "        H = self.kernel(X, X) * self.kernel(y, y)\n",
    "        \n",
    "        # Converting into cvxopt format \n",
    "        P = cvxopt.matrix(H)\n",
    "        q = cvxopt.matrix(-np.ones((n, 1)))\n",
    "        G = cvxopt.matrix(np.vstack((np.eye(n)*-1, np.eye(n))))\n",
    "        h = cvxopt.matrix(np.hstack((np.zeros(n), np.ones(n) * self.C)))\n",
    "        A = cvxopt.matrix(y.reshape(1, -1))\n",
    "        b = cvxopt.matrix(np.zeros(1))\n",
    "        \n",
    "        a = cvxopt_solve_qp(P=P, q=q, G=G, h=h, A=A, b=b)\n",
    "        ind_sv = np.where(a > tol_sv)\n",
    "        self.a = a[ind_sv]\n",
    "        self.X_sv = X[ind_sv]\n",
    "        self.t_sv = t[ind_sv]\n",
    "        b = self.t_sv - self.kernel(self.X_sv, self.X_sv) @ (self.a*self.t_sv)\n",
    "        self.b = sum(b) / len(b)\n",
    "        \n",
    "        ind_unbounded_sv = np.where( np.round(self.a, 2) < self.C)\n",
    "        self.ind_unbounded_sv = ind_unbounded_sv\n",
    "        unbounded_X_sv = self.X_sv[ind_unbounded_sv]\n",
    "        unbounded_t_sv = self.t_sv[ind_unbounded_sv]\n",
    "        b = unbounded_t_sv - self.kernel(unbounded_X_sv, self.X_sv) @ (self.a*self.t_sv)\n",
    "        if len(b):\n",
    "            self.b = sum(b) / len(b)\n",
    "        \n",
    "        self.coef_ = self.X_sv.T @ (self.a*self.t_sv)\n",
    "        self.support_ = ind_sv\n",
    "        self.n_support_ = [np.count_nonzero(self.t_sv < 0), np.count_nonzero(self.t_sv > 0)]\n",
    "            \n",
    "    def decision_function(self, X):\n",
    "        val_dec_func = self.kernel(X, self.X_sv) @ (self.a*self.t_sv) + self.b\n",
    "        return val_dec_func \n",
    "    \n",
    "    def predict(self,X):\n",
    "        pred = np.sign(self.decision_function(X))\n",
    "        return pred\n",
    "    \n",
    "    def details(self):\n",
    "        print(\"____________\")\n",
    "        if type(self.kernel) == LinearKernel:\n",
    "            print('w = ', self.coef_)\n",
    "        print('b = ', self.b)\n",
    "        print('Indices of support vectors = ', self.support_)\n",
    "        # print('Support vectors = ', clf.support_vectors_)\n",
    "        print('Number of support vectors for each class = ', self.n_support_)\n",
    "        print('Coefficients of the support vector in the decision function = ', self.a)\n",
    "        print()\n",
    "        \n",
    "\n",
    "class MultiClass_SVC:\n",
    "    def __init__(self, kernel, C=1.0, num_lables=10):\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.num_lables = num_lables\n",
    "    \n",
    "    def fit(self, X, y, tol_conv=1e-6, tol_sv=1e-4, show_time = False): \n",
    "        self.train_X = X\n",
    "        self.train_y = y\n",
    "        self.classifiers = [None for i in range(self.num_lables)]\n",
    "        for num in range(0, self.num_lables):\n",
    "            train_y = np.where(y == num, 1, -1).astype(int)\n",
    "            svc = SVC(C=self.C, kernel=self.kernel)\n",
    "            svc.fit(X, train_y)\n",
    "            self.classifiers[num] = svc\n",
    "            \n",
    "    def decision_function(self, X):\n",
    "        classProbabilities = np.array([self.classifiers[i].decision_function(X) \n",
    "                                       for i in range(self.num_lables)]).T\n",
    "        return classProbabilities \n",
    "    \n",
    "    def predict(self,X):\n",
    "        classProbabilities = self.decision_function(X)\n",
    "        pred = classProbabilities.argmax(axis=1)\n",
    "        return pred\n",
    "    \n",
    "    def get_accuracy(self, X, Y):\n",
    "        return np.sum(Y == self.predict(X)) / len(Y)\n",
    "    \n",
    "    def print_accuracy(self, train_X, train_y, test_X, test_y):\n",
    "        print(f\"train accuracy score: {self.get_accuracy(train_X, train_y)}\")\n",
    "        print(f\"test accuracy score: {self.get_accuracy(test_X, test_y)}\")\n",
    "    \n",
    "    def print_confusion_matrix(self, _X, _y):    \n",
    "        predicts = self.predict(_X)\n",
    "        confusion_matrix = [[0 for i in range(self.num_lables)] for j in range(self.num_lables)]\n",
    "        for i in range(len(_y)):\n",
    "            confusion_matrix[_y[i]][predicts[i]] += 1\n",
    "\n",
    "        df = pd.DataFrame(confusion_matrix, columns=['Pred' + str(i) for i in range(10)], \n",
    "                          index=['Class ' + str(i) for i in range(10)])\n",
    "        print(df)\n",
    "\n",
    "    def show_result(self, test_X, test_y):\n",
    "        self.print_accuracy(self.train_X, self.train_y, test_X, test_y)\n",
    "        print()\n",
    "        print(\"Confusion Matrix of train data:\")\n",
    "        self.print_confusion_matrix(self.train_X, self.train_y)\n",
    "        print()\n",
    "        print(\"Confusion Matrix of test data:\")\n",
    "        self.print_confusion_matrix(test_X, test_y)\n",
    "        print(\"\\n_______________________\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_fold_CV(X, Y, fold_num=4):\n",
    "    data_size = len(X)\n",
    "    fold_size = int(data_size / fold_num)\n",
    "    \n",
    "    validation_sets = [None for i in range(fold_num)]\n",
    "    train_sets = [None for i in range(fold_num)] \n",
    "    data = range(data_size)\n",
    "    \n",
    "    for i in range(fold_num):\n",
    "        n_sample = fold_size\n",
    "        if i == fold_num - 1:\n",
    "            n_sample = data_size - (fold_num - 1) * fold_size\n",
    "        fold_ind = np.array(np.random.choice(data, n_sample, replace=False))\n",
    "        data = np.setdiff1d(data, fold_ind)\n",
    "        \n",
    "        validation_sets[i] = {'X': X[fold_ind], 'Y': Y[fold_ind]}\n",
    "        rest_ind = np.setdiff1d(range(data_size), fold_ind)\n",
    "        train_sets[i] = {'X': X[rest_ind], 'Y': Y[rest_ind]}\n",
    "    \n",
    "    return train_sets, validation_sets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section B\n",
      "______________________________________\n",
      "\n",
      "[0.9153253978610382, 0.9590037978262406, 0.9796053740464655, 0.9903168344017268]\n",
      "--------------\n",
      "-> Result of 4-fold cross validation for Linear Kernel:\n",
      "    Best parameter C is: 100.0 \n",
      "     with average validation accuracy = 0.9903168344017268\n",
      "\n",
      "-> Result of traing Soft Margin SVM using QP optimization with best learned parameter C = 100.0:\n",
      "\n",
      "train accuracy score: 0.9894932014833128\n",
      "test accuracy score: 0.9441340782122905\n",
      "\n",
      "Confusion Matrix of train data:\n",
      "         Pred0  Pred1  Pred2  Pred3  Pred4  Pred5  Pred6  Pred7  Pred8  Pred9\n",
      "Class 0    161      0      0      0      0      0      0      0      0      0\n",
      "Class 1      0    161      0      0      0      1      1      0      1      0\n",
      "Class 2      0      0    160      0      0      0      0      0      0      0\n",
      "Class 3      0      0      0    162      0      0      0      0      2      0\n",
      "Class 4      0      0      0      0    164      0      0      0      0      0\n",
      "Class 5      0      0      0      0      0    162      0      0      0      1\n",
      "Class 6      0      0      0      0      0      0    163      0      0      0\n",
      "Class 7      0      0      0      0      0      0      0    160      0      1\n",
      "Class 8      0      6      1      1      0      0      0      0    149      0\n",
      "Class 9      1      0      0      1      0      0      0      0      0    159\n",
      "\n",
      "Confusion Matrix of test data:\n",
      "         Pred0  Pred1  Pred2  Pred3  Pred4  Pred5  Pred6  Pred7  Pred8  Pred9\n",
      "Class 0     17      0      0      0      0      0      0      0      0      0\n",
      "Class 1      0     16      0      0      1      0      0      0      0      1\n",
      "Class 2      0      0     17      0      0      0      0      0      0      0\n",
      "Class 3      0      0      0     17      0      0      0      0      1      1\n",
      "Class 4      0      0      0      0     17      0      0      0      0      0\n",
      "Class 5      0      0      0      0      0     19      0      0      0      0\n",
      "Class 6      0      1      0      0      0      0     17      0      0      0\n",
      "Class 7      0      0      0      0      0      0      0     17      0      1\n",
      "Class 8      0      2      0      0      0      1      0      0     14      0\n",
      "Class 9      0      0      0      0      0      0      0      0      1     18\n",
      "\n",
      "_______________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Section B\")\n",
    "print(\"______________________________________\")\n",
    "print()\n",
    "\n",
    "# CC = [0.1] + [i for i in range(1, 10)] + [10 * i for i in range(1, 11)]\n",
    "CC = [0.1, 1.0, 10, 100.0]\n",
    "\n",
    "accs = [0 for i in range(len(CC))]\n",
    "folds_num = 4\n",
    "\n",
    "kernel = LinearKernel()\n",
    "train_sets, validation_sets = four_fold_CV(train_X, train_Y, folds_num)\n",
    "\n",
    "for (cntC, C) in enumerate(CC):\n",
    "    svc = MultiClass_SVC(C=C, kernel=kernel)\n",
    "    \n",
    "    avg_acc = 0\n",
    "    for i in range(folds_num):\n",
    "        t_X = train_sets[i]['X']\n",
    "        t_Y = train_sets[i]['Y']\n",
    "        v_X = train_sets[i]['X']\n",
    "        v_Y = train_sets[i]['Y']\n",
    "        \n",
    "        try:\n",
    "            svc.fit(t_X, t_Y)\n",
    "            avg_acc += svc.get_accuracy(v_X, v_Y)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "        \n",
    "    accs[cntC] = avg_acc / folds_num\n",
    "  \n",
    "\n",
    "print(accs)\n",
    "print(\"--------------\")\n",
    "print(\"-> Result of 4-fold cross validation for Linear Kernel:\")\n",
    "c_ind = np.argmax(accs)\n",
    "best_C = CC[c_ind]\n",
    "print(\"    Best parameter C is:\", best_C, \"\\n\", \n",
    "      \"    with average validation accuracy =\", accs[c_ind])\n",
    "print()\n",
    "\n",
    "print(\"-> Result of traing Soft Margin SVM using QP optimization with best learned parameter C =\", str(best_C) + \":\")\n",
    "print()\n",
    "svc = MultiClass_SVC(C=best_C, kernel=kernel)\n",
    "svc.fit(train_X, train_Y)\n",
    "svc.show_result(test_X, test_Y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section P\n",
      "______________________________________\n",
      "\n",
      "[[0.3515140331990365, 0.7011291532777659, 0.8920521582636023, 0.9719832156197498, 0.9995877985656886], [0.3515140331990365, 0.7011291532777659, 0.8920521582636023, 0.9719832156197498, 0.9995877985656886]]\n",
      "--------------\n",
      "-> Result of 4-fold cross validation for Gaussian Kernel:\n",
      "    Best parameter C is: 10.0 \n",
      "    Best parameter sigm s: 0.2 \n",
      "    with average validation accuracy = 0.9995877985656886\n",
      "\n",
      "-> Result of traing Soft Margin SVM using QP optimization \n",
      "    with best learned parameter C = 10.0 and sigma = 0.2:\n",
      "\n",
      "train accuracy score: 0.9993819530284301\n",
      "test accuracy score: 0.9888268156424581\n",
      "\n",
      "Confusion Matrix of train data:\n",
      "         Pred0  Pred1  Pred2  Pred3  Pred4  Pred5  Pred6  Pred7  Pred8  Pred9\n",
      "Class 0    161      0      0      0      0      0      0      0      0      0\n",
      "Class 1      0    163      0      0      0      0      0      0      1      0\n",
      "Class 2      0      0    160      0      0      0      0      0      0      0\n",
      "Class 3      0      0      0    164      0      0      0      0      0      0\n",
      "Class 4      0      0      0      0    164      0      0      0      0      0\n",
      "Class 5      0      0      0      0      0    163      0      0      0      0\n",
      "Class 6      0      0      0      0      0      0    163      0      0      0\n",
      "Class 7      0      0      0      0      0      0      0    161      0      0\n",
      "Class 8      0      0      0      0      0      0      0      0    157      0\n",
      "Class 9      0      0      0      0      0      0      0      0      0    161\n",
      "\n",
      "Confusion Matrix of test data:\n",
      "         Pred0  Pred1  Pred2  Pred3  Pred4  Pred5  Pred6  Pred7  Pred8  Pred9\n",
      "Class 0     17      0      0      0      0      0      0      0      0      0\n",
      "Class 1      0     18      0      0      0      0      0      0      0      0\n",
      "Class 2      0      0     17      0      0      0      0      0      0      0\n",
      "Class 3      0      0      0     18      0      0      0      1      0      0\n",
      "Class 4      0      0      0      0     17      0      0      0      0      0\n",
      "Class 5      0      0      0      0      0     19      0      0      0      0\n",
      "Class 6      0      0      0      0      0      0     18      0      0      0\n",
      "Class 7      0      0      0      0      0      0      0     18      0      0\n",
      "Class 8      0      0      0      0      0      0      0      0     17      0\n",
      "Class 9      0      0      0      1      0      0      0      0      0     18\n",
      "\n",
      "_______________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Section P\")\n",
    "print(\"______________________________________\")\n",
    "print()\n",
    "\n",
    "# ss = [0.1 * i for i in range(10, 0, -1)]\n",
    "# CC = [10 * i for i in range(1, 11)]\n",
    "\n",
    "ss = [0.1 * i for i in range(10, 0, -2)]\n",
    "CC = [10., 100.]\n",
    "\n",
    "\n",
    "accs = [[0 for j in range(len(ss))] for i in range(len(CC))]\n",
    "folds_num = 4\n",
    "\n",
    "train_sets, validation_sets = four_fold_CV(train_X, train_Y, folds_num)\n",
    "\n",
    "for (cnts, s) in enumerate(ss):\n",
    "    for (cntC, C) in enumerate(CC):\n",
    "        kernel = GaussianKernel(theta=s)\n",
    "        svc = MultiClass_SVC(C=C, kernel=kernel)\n",
    "\n",
    "        avg_acc = 0\n",
    "        for i in range(folds_num):\n",
    "            t_X = train_sets[i]['X']\n",
    "            t_Y = train_sets[i]['Y']\n",
    "            v_X = train_sets[i]['X']\n",
    "            v_Y = train_sets[i]['Y']\n",
    "\n",
    "            try:\n",
    "                svc.fit(t_X, t_Y)\n",
    "                avg_acc += svc.get_accuracy(v_X, v_Y)\n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "\n",
    "        accs[cntC][cnts] = avg_acc / folds_num\n",
    "\n",
    "print(accs)\n",
    "print(\"--------------\")\n",
    "print(\"-> Result of 4-fold cross validation for Gaussian Kernel:\")\n",
    "\n",
    "s_ind = int(np.argmax(accs) % len(ss))\n",
    "c_ind = int((np.argmax(accs) - s_ind) / len(ss))\n",
    "best_C = CC[c_ind]\n",
    "best_s = ss[s_ind]\n",
    "\n",
    "print(\"    Best parameter C is:\", best_C, \"\\n\",\n",
    "      \"   Best parameter sigm s:\", best_s, \"\\n\",\n",
    "      \"   with average validation accuracy =\", accs[c_ind][s_ind])\n",
    "print()\n",
    "\n",
    "print(\"-> Result of traing Soft Margin SVM using QP optimization \\n\",\n",
    "      \"   with best learned parameter C =\", best_C, \"and sigma =\", str(best_s) + \":\")\n",
    "print()\n",
    "\n",
    "kernel = GaussianKernel(theta=best_s)\n",
    "svc = MultiClass_SVC(C=best_C, kernel=kernel)\n",
    "svc.fit(train_X, train_Y)\n",
    "svc.show_result(test_X, test_Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
